\documentclass[11pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{graphicx}
%\usepackage[colorinlistoftodos]{todonotes}

\title{CS434 Final Project Report (3-page limit)}
\author{Aaron Leondar, Alex Ruef, Ross Shoger}
\date{}
\begin{document}
\maketitle
\section{Feature formulation and preprocessing}
\subsection{Features} What are the features you feed to your learning algorithm? Did you simply flatten the 7 rows into a vector for features? Did you transform or aggregate the given data to engineer your own features?

To get our features we put together the 30 minute data intervals and then flatten each instance into a vector.

\subsection{Preprocessing}
Did you pre-process your data in any way? This can be for the purpose of reducing dimension, or reducing noise, or balancing the class distribution. Be clear about what you exactly did. The criterion is to allow others to replicate your works.

We did not do any preprocessing on our data besides creating the instances.

\section{Learning algorithms}
\subsection{Algorithms explored}
Provide a list of learning algorithms that you explored for this project. For each algorithm, briefly justify your rationale for choosing this algorithm.

\subsection{Final models}
What are the final models that produced your submitted test predictions?

\section{Parameter Tuning and Model Selection }
\subsection{Parameter Tuning}
What parameters did you tune for your models? How do you perform the parameter tuning?

\subsubsection{Decision Tree}
Originally we were using the Gini criterion for decision tree branching which got us good results on the training set but we were getting no positive predictions on the test set.
Changing the criterion to use entropy gave us a slightly higher prediction rate on the training set and gave us some positive predictions on the final test set.

\subsubsection{SVC}
Tried out different kernels, mostly tested with sigmoid and different polynomials.
Any polynomial with degree larger than 3 took too long to finish and we got mostly false positives with polynomial.

\subsubsection{Neural Network}
We tried adjusting many of the parameters such as the number of hidden layers and max iterations.
We found the default setting was best for many of the parameters.
We settled on using a relu activation function with an Ibgfs solver for weight distribution.
The hard part with Neural Network is we often get no positive predictions and other times it is normal.

\subsection{Model selection}
How did you decide which models to use to produce the final predictions?  Do you use cross-validation or hold-out for model selection? When you split the data for validation, is it fully random or special consideration went into forming the folds? What criterion is used to select the models?

\section{Results}
Do you have any internal evaluation results you want to report?

\end{document}