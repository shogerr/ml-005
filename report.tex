\documentclass[11pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{graphicx}
%\usepackage[colorinlistoftodos]{todonotes}

\title{CS434 Final Project Report (3-page limit)}
\author{Aaron Leondar, Alex Ruef, Ross Shoger}
\date{6/13/2018}
\begin{document}
\maketitle
\section{Feature formulation and preprocessing}
	\subsection{Features}
	To get our features we put together the 30 minute data intervals and then flatten each instance into a vector.

	\subsection{Preprocessing}
		Did you pre-process your data in any way?
		This can be for the purpose of reducing dimension, or reducing noise, or balancing the class distribution.
		Be clear about what you exactly did.
		The criterion is to allow others to replicate your works.

		We did not do any preprocessing on our data besides creating the instances.

\section{Learning algorithms}
	\subsection{Algorithms explored}
		\subsubsection{Neural Network}
			Neural networks are all the rage right now and it is a powerful algorithm so we wanted to try it out.

		\subsubsection{Decision Tree}
			We liked decision tree when we used it in previous assignments.
			We thought our better understanding of this algorithm could boost our success rate.

		\subsubsection{SVC}
			Support Vector Clustering seemed like a powerful algorithm to use in order to separate the data into definite groups.

		\subsubsection{Naive Bayes}
			Naive Bayes is highly scalable, and therefore has a good probability to handle a large amount of data sets, which would could work well for this project.

		\subsubsection{Logistic Regression}
			We chose Logistic Regression due to it being especially good (in fact being the go-to method) for binary classification problems, which is what this project is, since our prediction value is a binary number. 1 = Hypo event, 0 = non-Hypo event.

	\subsection{Final models}
		\begin{enumerate}
			\item Neural Network
			\item Decision Tree
			\item Logistic Regression
		\end{enumerate}

\section{Parameter Tuning and Model Selection }
	\subsection{Parameter Tuning}

		\subsubsection{Decision Tree}
			Originally we were using the Gini criterion for decision tree branching which got us good results on the training set but we were getting no positive predictions on the test set.
			Changing the criterion to use entropy gave us a slightly higher prediction rate on the training set and gave us some positive predictions on the final test set.

		\subsubsection{SVC}
			Tried out different kernels, mostly tested with sigmoid and different polynomials.
			Any polynomial with degree larger than 3 took too long to finish and we got mostly false positives with polynomial.

		\subsubsection{Neural Network}
			We tried adjusting many of the parameters such as the number of hidden layers and max iterations.
			We found the default setting was best for many of the parameters.
			We settled on using a relu activation function with an Ibgfs solver for weight distribution.
			The hard part with Neural Network is we often get no positive predictions and other times it is normal.

		\subsubsection{Naive Bayes}
			For Naive Bayes we used a GaussianNB algorithm which didn't have much parameters to change besides priors which didn't apply in our situation.
			The success rate was so low early on we didn't put much effort into this one.

		\subsubsection{Logistic Regression}
			We tried different solver methods like sag and saga but they gave us lower precision rates so we stuck with the default liblinear solver.
			We also tried lower and increasing the tolerance for the stopping criteria and saw no changes to precision and recall.
			Reducing the strength of the regularization got us a small boost in precision.

	\subsection{Model selection}
		We used hold out validation to test our algorithms.
		We were really interested in how many true positives our algorithms were getting.
		Since there are so little positive values in the data set we made the test data set larger than the training set so the algorithms had a chance to find more true positives.
		With holdout validation we looked for algorithms that had high precision and recall rates to use as our top 3 algortihms.

\section{Results}
	Do you have any internal evaluation results you want to report?

	\begin{tabular}{ | l | r | r | r | }
		\hline
		Algorithm & Precision & Recall & Overall Success Rate \\
		\hline
		Naive Bayes & 5\% & 1\% & 63\% \\
		\hline
		Neural Network & 39\% & 3\% & 97\% \\
		\hline
		Decision Tree & 25\% & 2\% & 96\% \\
		\hline
		SVC & 3\% & 0\% & 3\% \\
		\hline
		Logistic Regression & 21\% & 1\% & 93\% \\
		\hline
	\end{tabular}

\end{document}
