\documentclass[11pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{graphicx}
%\usepackage[colorinlistoftodos]{todonotes}

\title{CS434 Final Project Report (3-page limit)}
\author{Aaron Leondar, Alex Ruef, Ross Shoger}
\date{}
\begin{document}
\maketitle
\section{Feature formulation and preprocessing}
	\subsection{Features}
	What are the features you feed to your learning algorithm?
	Did you simply flatten the 7 rows into a vector for features?
	Did you transform or aggregate the given data to engineer your own features?

	To get our features we put together the 30 minute data intervals and then flatten each instance into a vector.

	\subsection{Preprocessing}
		Did you pre-process your data in any way?
		This can be for the purpose of reducing dimension, or reducing noise, or balancing the class distribution.
		Be clear about what you exactly did.
		The criterion is to allow others to replicate your works.

		We did not do any preprocessing on our data besides creating the instances.

\section{Learning algorithms}
	\subsection{Algorithms explored}
		Provide a list of learning algorithms that you explored for this project.
		For each algorithm, briefly justify your rationale for choosing this algorithm.

		\subsubsection{Neural Network}
			Neural networks are all the rage right now and its a powerful algorithm so we wanted to try it out.

		\subsubsection{Decision Tree}
			We liked decision tree when we used it in previous assignments.
			We though our better understanding of this algorithm could boost our success rate.

		\subsubsection{SVC}

		\subsubsection{Naive Bayes}

		\subsubsection{Logistic Regression}

	\subsection{Final models}
		What are the final models that produced your submitted test predictions?

\section{Parameter Tuning and Model Selection }
	\subsection{Parameter Tuning}
		What parameters did you tune for your models?
		How do you perform the parameter tuning?

		\subsubsection{Decision Tree}
			Originally we were using the Gini criterion for decision tree branching which got us good results on the training set but we were getting no positive predictions on the test set.
			Changing the criterion to use entropy gave us a slightly higher prediction rate on the training set and gave us some positive predictions on the final test set.

		\subsubsection{SVC}
			Tried out different kernels, mostly tested with sigmoid and different polynomials.
			Any polynomial with degree larger than 3 took too long to finish and we got mostly false positives with polynomial.

		\subsubsection{Neural Network}
			We tried adjusting many of the parameters such as the number of hidden layers and max iterations.
			We found the default setting was best for many of the parameters.
			We settled on using a relu activation function with an Ibgfs solver for weight distribution.
			The hard part with Neural Network is we often get no positive predictions and other times it is normal.

		\subsubsection{Naive Bayes}
			For Naive Bayes we used a GaussianNB algorithm which didn't have much parameters to change besides priors which didn't apply in our situation.

		\subsubsection{Logistic Regression}
			

	\subsection{Model selection}
		How did you decide which models to use to produce the final predictions? 
		Do you use cross-validation or hold-out for model selection?
		When you split the data for validation, is it fully random or special consideration went into forming the folds?
		What criterion is used to select the models?

		We used hold out validation to test our algorithms.
		We were really interested in how many true positives our algorithms were getting.
		Since there are so little positive values in the data set we made the test data set larger than the training set so the algorithms had a chance to find more true positives.
		With holdout validation we looked for algorithms that had high precision and recall rates.

\section{Results}
	Do you have any internal evaluation results you want to report?

	\begin{tabular}{ | l | r | r | r | }
		\hline
		Algorithm & Precision & Recall & Overall Success Rate \\
		\hline
		Naive Bayes & 5\% & 1\% & 63\% \\
		\hline
		Neural Network & 39\% & 3\% & 97\% \\
		\hline
	\end{tabular}

\end{document}